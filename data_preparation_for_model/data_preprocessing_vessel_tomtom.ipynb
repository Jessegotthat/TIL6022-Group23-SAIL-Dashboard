{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5c9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "FREQ = \"3min\"\n",
    "OUT_DIR = Path(\"outputs_fast\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOMTOM_CSV = r\"C:/Users/elvinli/OneDrive/CodeProjects/TomTom_data_20_24Aug2025.csv\"\n",
    "VESSEL_FILE = r\"C:/Users/elvinli/OneDrive/CodeProjects/Vesselposition_data_20_24Aug2025.csv\"\n",
    "\n",
    "CSV_ENGINE = \"c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370fd137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_from_inner_csv(s: str) -> float:\n",
    "    if not isinstance(s, str) or not s:\n",
    "        return np.nan\n",
    "    i = s.find(\"\\n\")\n",
    "    if i == -1:\n",
    "        return np.nan\n",
    "    total = 0.0\n",
    "    n = 0\n",
    "    for line in s[i+1:].splitlines():\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            total += float(line.rsplit(\",\", 1)[-1])\n",
    "            n += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "    return (total / n) if n else np.nan\n",
    "\n",
    "def build_tomtom_3min_static(file_path: str,\n",
    "                             out_path=OUT_DIR / \"tomtom_3min.parquet\",\n",
    "                             chunksize: int = 2000,\n",
    "                             engine: str = \"pyarrow\"):\n",
    "    ts_chunks, mean_chunks = [], []\n",
    "    for chunk in pd.read_csv(file_path, usecols=[\"time\", \"data\"],\n",
    "                             chunksize=chunksize, engine=engine, low_memory=False):\n",
    "        t = pd.to_datetime(chunk[\"time\"], utc=True, errors=\"coerce\").dt.tz_convert(None)\n",
    "        means = [_mean_from_inner_csv(s) for s in chunk[\"data\"].tolist()]\n",
    "        ts_chunks.append(t.values)\n",
    "        mean_chunks.append(np.array(means, dtype=\"float64\"))\n",
    "\n",
    "    if not ts_chunks:\n",
    "        raise ValueError(\"TomTom CSV data not analyzed\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": np.concatenate(ts_chunks),\n",
    "        \"traffic_level_mean\": np.concatenate(mean_chunks)\n",
    "    }).dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
    "\n",
    "    df_3min = (df.set_index(\"timestamp\")\n",
    "                 .resample(FREQ)[\"traffic_level_mean\"]\n",
    "                 .mean().to_frame().reset_index())\n",
    "\n",
    "    df_3min.to_parquet(out_path, index=False)\n",
    "    print(f\"[TomTom] Saving_Path:{out_path}  Shape={df_3min.shape}\")\n",
    "    return df_3min\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce528b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vessel_3min_static(file_path: str,\n",
    "                             out_path=OUT_DIR / \"vessel_3min.parquet\",\n",
    "                             convert_speed_to_mps=True,\n",
    "                             unique_boats=False,\n",
    "                             chunksize: int = 2_000_000,\n",
    "                             engine: str = \"pyarrow\",\n",
    "                             sep: str = \",\"):\n",
    "\n",
    "    # Head check\n",
    "    head = pd.read_csv(file_path, nrows=50, engine=engine, sep=sep, low_memory=False, on_bad_lines=\"skip\")\n",
    "    cols = list(head.columns)\n",
    "\n",
    "    # Match columns\n",
    "    TCOL = \"upload-timestamp\"\n",
    "    SCOL = \"speed-in-centimeters-per-second\"\n",
    "    ICOL = None\n",
    "    if unique_boats:\n",
    "        ICOL = \"id\" if \"id\" in cols else (\"mmsi-number\" if \"mmsi-number\" in cols else None)\n",
    "\n",
    "    if TCOL not in cols:\n",
    "        raise ValueError(f\"Time column not found '{TCOL}'; existed column example:{cols[:10]}\")\n",
    "    if SCOL not in cols:\n",
    "        raise ValueError(f\"Velocity column not found '{SCOL}'; existed column example:{cols[:10]}\")\n",
    "    if unique_boats and ICOL is None:\n",
    "        raise ValueError(\"unique_boats=True but no suitable ID column found; existed column example:{cols[:10]}\")\n",
    "\n",
    "    usecols = [TCOL, SCOL] + ([ICOL] if unique_boats else [])\n",
    "\n",
    "    # Universal accumulators\n",
    "    count_acc, speed_sum_acc, speed_cnt_acc = {}, {}, {}\n",
    "\n",
    "    TS_FORMAT = \"%Y-%m-%dT%H:%M:%S.%fZ\" \n",
    "\n",
    "    for chunk in pd.read_csv(file_path, usecols=usecols, chunksize=chunksize,\n",
    "                             engine=engine, sep=sep, low_memory=False, on_bad_lines=\"skip\"):\n",
    "        # Timestamp Parsing\n",
    "        ts = pd.to_datetime(chunk[TCOL], format=TS_FORMAT, utc=True, errors=\"coerce\")\n",
    "        miss = ts.isna()\n",
    "        if miss.any():\n",
    "            ts2 = pd.to_datetime(chunk.loc[miss, TCOL], utc=True, errors=\"coerce\")\n",
    "            ts.loc[miss] = ts2\n",
    "\n",
    "        ts = ts.dt.tz_convert(None) \n",
    "        chunk = chunk.assign(timestamp=ts).dropna(subset=[\"timestamp\"])\n",
    "\n",
    "        # Data Processing: Velocity\n",
    "        sp = pd.to_numeric(chunk[SCOL], errors=\"coerce\")\n",
    "        if convert_speed_to_mps:\n",
    "            sp = sp / 100.0\n",
    "        chunk[\"speed\"] = sp\n",
    "\n",
    "        # 3min binning\n",
    "        chunk[\"bin\"] = chunk[\"timestamp\"].dt.floor(FREQ)\n",
    "\n",
    "        # Count & Sum & N per bin\n",
    "        if unique_boats:\n",
    "            g_count = chunk.groupby(\"bin\")[ICOL].nunique()\n",
    "        else:\n",
    "            g_count = chunk.groupby(\"bin\").size()\n",
    "\n",
    "        g_sum = chunk.groupby(\"bin\")[\"speed\"].sum(min_count=1)\n",
    "        g_n   = chunk.groupby(\"bin\")[\"speed\"].count()\n",
    "\n",
    "        #Cumulate into global accumulators\n",
    "        for k, v in g_count.items():\n",
    "            count_acc[k] = count_acc.get(k, 0) + int(v)\n",
    "        for k, v in g_sum.items():\n",
    "            speed_sum_acc[k] = speed_sum_acc.get(k, 0.0) + float(v)\n",
    "        for k, v in g_n.items():\n",
    "            speed_cnt_acc[k] = speed_cnt_acc.get(k, 0) + int(v)\n",
    "\n",
    "    # Aggragate into DataFrame\n",
    "    bins = sorted(set(count_acc) | set(speed_sum_acc) | set(speed_cnt_acc))\n",
    "    vessel_count = pd.Series([count_acc.get(b, 0) for b in bins], index=bins, dtype=\"int64\").rename(\"vessel_count\")\n",
    "    vessel_avg_speed = (pd.Series([speed_sum_acc.get(b, np.nan) for b in bins], index=bins) /\n",
    "                        pd.Series([speed_cnt_acc.get(b, 0) for b in bins], index=bins)).rename(\"vessel_avg_speed\")\n",
    "\n",
    "    df_3min = pd.concat([vessel_count, vessel_avg_speed], axis=1).reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "    df_3min.to_parquet(out_path, index=False)\n",
    "    print(f\"[Vessel] Saving_Path={out_path}  Shape={df_3min.shape}\")\n",
    "    return df_3min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c1cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TomTom] Saving_Path:outputs_fast\\tomtom_3min.parquet  Shape=(2188, 2)\n",
      "[Vessel] Saving_Path=outputs_fast\\vessel_3min.parquet  Shape=(1802, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>traffic_level_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-20 06:36:00</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-20 06:39:00</td>\n",
       "      <td>0.816597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-20 06:42:00</td>\n",
       "      <td>0.810953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-20 06:45:00</td>\n",
       "      <td>0.800038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-20 06:48:00</td>\n",
       "      <td>0.800142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  traffic_level_mean\n",
       "0 2025-08-20 06:36:00            0.825112\n",
       "1 2025-08-20 06:39:00            0.816597\n",
       "2 2025-08-20 06:42:00            0.810953\n",
       "3 2025-08-20 06:45:00            0.800038\n",
       "4 2025-08-20 06:48:00            0.800142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>vessel_count</th>\n",
       "      <th>vessel_avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-20 06:27:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-20 06:30:00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-20 06:33:00</td>\n",
       "      <td>3903</td>\n",
       "      <td>2.840430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-20 06:36:00</td>\n",
       "      <td>5821</td>\n",
       "      <td>3.025631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-20 06:39:00</td>\n",
       "      <td>5900</td>\n",
       "      <td>2.931915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  vessel_count  vessel_avg_speed\n",
       "0 2025-08-20 06:27:00            12          2.408333\n",
       "1 2025-08-20 06:30:00            30          1.023333\n",
       "2 2025-08-20 06:33:00          3903          2.840430\n",
       "3 2025-08-20 06:36:00          5821          3.025631\n",
       "4 2025-08-20 06:39:00          5900          2.931915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tt = build_tomtom_3min_static(TOMTOM_CSV, engine=CSV_ENGINE)\n",
    "vs = build_vessel_3min_static(VESSEL_FILE, engine=CSV_ENGINE)\n",
    "\n",
    "display(tt.head())\n",
    "display(vs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb53ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomTom CSV Saved: outputs_fast\\tomtom_3min.csv, Shape=(2188, 2)\n",
      "Vessel CSV Saved: outputs_fast\\vessel_3min.csv, Shape=(1802, 3)\n"
     ]
    }
   ],
   "source": [
    "# === Convert parquet outputs to CSV ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"data_preprocessing_for_model\")\n",
    "\n",
    "tomtom_path = OUT_DIR / \"tomtom_3min.parquet\"\n",
    "vessel_path = OUT_DIR / \"vessel_3min.parquet\"\n",
    "\n",
    "tt = pd.read_parquet(tomtom_path)\n",
    "vs = pd.read_parquet(vessel_path)\n",
    "\n",
    "# Standardize timestamp format\n",
    "tt[\"timestamp\"] = pd.to_datetime(tt[\"timestamp\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "vs[\"timestamp\"] = pd.to_datetime(vs[\"timestamp\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Export CSV\n",
    "tt_csv_path = OUT_DIR / \"tomtom_3min.csv\"\n",
    "vs_csv_path = OUT_DIR / \"vessel_3min.csv\"\n",
    "\n",
    "tt.to_csv(tt_csv_path, index=False, float_format=\"%.6f\")\n",
    "vs.to_csv(vs_csv_path, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(f\"TomTom CSV Saved: {tt_csv_path}, Shape={tt.shape}\")\n",
    "print(f\"Vessel CSV Saved: {vs_csv_path}, Shape={vs.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
