{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23336e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomTom tidy shape: (5177644, 3)\n",
      "          id  traffic_level                             time\n",
      "0  213399051           0.49 2025-08-20 08:37:13.722331+02:00\n",
      "1  247378050           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "2  247379106           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "3  247380059           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "4  247380066           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "5  247381056           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "6  248367009           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "7  248370083           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "8  247378009           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "9  248372134           1.00 2025-08-20 08:37:13.722331+02:00\n",
      "time range: 2025-08-20 08:37:13.722331+02:00 -> 2025-08-20 16:29:56.126985+02:00\n",
      "unique links: 10742\n",
      "Vessel tidy shape: (1059291, 33)\n",
      "   identifier-sensor  radar-length-cm  radar-beam-cm  position-x  position-y  \\\n",
      "0                251             2500           1200    100561.0    497650.0   \n",
      "1              13212             2000            600    100329.0    497504.0   \n",
      "2                390             3300           1200    106036.0    498034.0   \n",
      "3                392             3600            800    105998.0    497971.0   \n",
      "4              10247             2000            300    106238.0    497017.0   \n",
      "5              11749             2500            600    106872.0    496420.0   \n",
      "6              12904             1200            300    107582.0    495802.0   \n",
      "7              12563             2400            600    107854.0    495575.0   \n",
      "8                216             2900            600    108308.0    495096.0   \n",
      "9              10199             2400            500    108497.0    494999.0   \n",
      "\n",
      "   speed-in-centimeters-per-second  x-speed  y-speed  orientation  \\\n",
      "0                               30      -15      -26        209.9   \n",
      "1                              160     -151       53        289.5   \n",
      "2                                0        0        0          0.1   \n",
      "3                                0        0        0          0.1   \n",
      "4                              240     -196      138        305.2   \n",
      "5                              220     -171      138        308.8   \n",
      "6                              260     -201      165        309.3   \n",
      "7                              240     -184      154        309.9   \n",
      "8                              300     -234      188        308.8   \n",
      "9                              180     -131      123        313.2   \n",
      "\n",
      "   significant-orientation  ...    beam   port-role  \\\n",
      "0                      NaN  ...  1100.0  TUG_VESSEL   \n",
      "1                      NaN  ...   600.0        None   \n",
      "2                      0.1  ...  1200.0        None   \n",
      "3                      0.1  ...   700.0        None   \n",
      "4                      NaN  ...   400.0        None   \n",
      "5                      NaN  ...   500.0        None   \n",
      "6                      NaN  ...   300.0        None   \n",
      "7                      NaN  ...   400.0        None   \n",
      "8                      NaN  ...   600.0        None   \n",
      "9                      NaN  ...   500.0        None   \n",
      "\n",
      "   short-term-avg-speed-in-cm-per-sec       lon        lat  \\\n",
      "0                                97.0  4.586152  52.463890   \n",
      "1                               165.0  4.582762  52.462554   \n",
      "2                                 0.0  4.666652  52.467857   \n",
      "3                                 0.0  4.666102  52.467288   \n",
      "4                               249.0  4.669773  52.458736   \n",
      "5                               219.0  4.679186  52.453427   \n",
      "6                               267.0  4.689717  52.447935   \n",
      "7                               239.0  4.693750  52.445918   \n",
      "8                               243.0  4.700494  52.441652   \n",
      "9                               189.0  4.703287  52.440797   \n",
      "\n",
      "                     id             upload-timestamp  oud_bericht  \\\n",
      "0  14523957174087988532  2025-08-20T06:34:08.177626Z        False   \n",
      "1   8410171728078482327  2025-08-20T06:34:08.181693Z        False   \n",
      "2  15111480980279746939  2025-08-20T06:34:08.196046Z        False   \n",
      "3   8852227552724661228  2025-08-20T06:34:08.200039Z        False   \n",
      "4  10343720115976443926  2025-08-20T06:34:08.215690Z        False   \n",
      "5    851979430478834452  2025-08-20T06:34:08.222713Z        False   \n",
      "6   6613863698192555741  2025-08-20T06:34:08.228385Z        False   \n",
      "7  16791222818394615857  2025-08-20T06:34:08.233041Z        False   \n",
      "8   6539153375085615249  2025-08-20T06:34:08.240610Z        False   \n",
      "9   9357413180969610565  2025-08-20T06:34:08.244866Z        False   \n",
      "\n",
      "   stale_since name  \n",
      "0          NaN  NaN  \n",
      "1          NaN  NaN  \n",
      "2          NaN  NaN  \n",
      "3          NaN  NaN  \n",
      "4          NaN  NaN  \n",
      "5          NaN  NaN  \n",
      "6          NaN  NaN  \n",
      "7          NaN  NaN  \n",
      "8          NaN  NaN  \n",
      "9          NaN  NaN  \n",
      "\n",
      "[10 rows x 33 columns]\n",
      "Found lat/lon columns: lat, lon\n",
      "         lat       lon\n",
      "0  52.463890  4.586152\n",
      "1  52.462554  4.582762\n",
      "2  52.467857  4.666652\n",
      "3  52.467288  4.666102\n",
      "4  52.458736  4.669773\n",
      "Found lat/lon columns: lat, lon\n",
      "         lat       lon\n",
      "0  52.463890  4.586152\n",
      "1  52.462554  4.582762\n",
      "2  52.467857  4.666652\n",
      "3  52.467288  4.666102\n",
      "4  52.458736  4.669773\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 通用：把 _value 从十六进制还原成 Python 对象 ----------\n",
    "def decode_value(hex_like: str):\n",
    "    \"\"\"把看起来像 hex 的字符串解成 JSON（失败返回 None）\"\"\"\n",
    "    try:\n",
    "        # 仅保留 0-9a-fA-F，去掉换行和控制字符\n",
    "        cleaned = ''.join(ch for ch in str(hex_like) if ch.isalnum())\n",
    "        b = bytes.fromhex(cleaned)\n",
    "        s = b.decode('utf-8', errors='ignore')\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------- 1) 读取与解析 TomTom ----------\n",
    "tomtom_raw = pd.read_parquet(\n",
    "    'data/20250820163000_stream.tomtom.analyze-sail.parquet', engine='fastparquet'\n",
    ")\n",
    "\n",
    "# 把 _value 解出来（得到包含 time 和 data 的字典）\n",
    "tomtom_decoded = tomtom_raw['_value'].map(decode_value)\n",
    "\n",
    "# 只保留解码成功的\n",
    "tomtom_decoded = [d for d in tomtom_decoded if isinstance(d, dict)]\n",
    "\n",
    "# 每条记录的 d['data'] 是一段 CSV 文本；逐条读成 DataFrame 并加上 time 列\n",
    "frames = []\n",
    "for d in tomtom_decoded:\n",
    "    time_str = d.get('time')  # 例如 '2025-08-20T08:37:13.722331+02:00'\n",
    "    csv_blob = d.get('data', '')\n",
    "    if not csv_blob:\n",
    "        continue\n",
    "    df_piece = pd.read_csv(StringIO(csv_blob))  # 有表头：id,traffic_level\n",
    "    df_piece['time'] = pd.to_datetime(time_str)  # 加时间戳\n",
    "    frames.append(df_piece)\n",
    "\n",
    "tomtom = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(columns=['id','traffic_level','time'])\n",
    "\n",
    "# 排序 & 简单预览\n",
    "tomtom = tomtom.sort_values('time').reset_index(drop=True)\n",
    "print('TomTom tidy shape:', tomtom.shape)\n",
    "print(tomtom.head(10))\n",
    "\n",
    "# 可选：看看时间范围、id 数量\n",
    "if not tomtom.empty:\n",
    "    print('time range:', tomtom['time'].min(), '->', tomtom['time'].max())\n",
    "    print('unique links:', tomtom['id'].nunique())\n",
    "\n",
    "# ---------- 2) 读取与解析 Vessel ----------\n",
    "import re, json, binascii\n",
    "\n",
    "def decode_value_fuzzy(val):\n",
    "    \"\"\"\n",
    "    尝试把 Kafka/FME 风格的 _value 解成 dict：\n",
    "    1) 优先按十六进制解析成 bytes\n",
    "    2) 从 bytes 里截取第一段 {...} 的 JSON 子串\n",
    "    3) 解析 JSON，失败则返回 None\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "\n",
    "    # 先尽量取出十六进制（允许换行/空格）\n",
    "    hex_candidate = re.sub(r'\\s+', '', s)\n",
    "    is_hex = bool(re.fullmatch(r'[0-9a-fA-F]+', hex_candidate)) and (len(hex_candidate) % 2 == 0)\n",
    "\n",
    "    b = None\n",
    "    if is_hex:\n",
    "        try:\n",
    "            b = bytes.fromhex(hex_candidate)\n",
    "        except binascii.Error:\n",
    "            b = None\n",
    "\n",
    "    # 如果不是纯 hex，就当作原始 utf-8 文本\n",
    "    if b is None:\n",
    "        b = s.encode('utf-8', errors='ignore')\n",
    "\n",
    "    # 在字节流里找 JSON 子串\n",
    "    lb = b.find(b'{')\n",
    "    rb = b.rfind(b'}')\n",
    "    if lb != -1 and rb != -1 and rb > lb:\n",
    "        js = b[lb:rb+1].decode('utf-8', errors='ignore')\n",
    "        try:\n",
    "            return json.loads(js)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# ---------- 解析 Vessel ----------\n",
    "vessel_raw = pd.read_parquet(\n",
    "    'data/20250820163000_stream.vessel-positions-anonymized-processed.analyze-sail.parquet',\n",
    "    engine='fastparquet'\n",
    ")\n",
    "\n",
    "vessel_decoded = [decode_value_fuzzy(x) for x in vessel_raw['_value']]\n",
    "vessel_decoded = [d for d in vessel_decoded if isinstance(d, dict)]\n",
    "\n",
    "# 展平（用 sep='.' 让嵌套键变成 position.lat 这种平面列）\n",
    "vessel = pd.json_normalize(vessel_decoded, sep='.')\n",
    "\n",
    "# 统一时间列（按你实际的键名，自行增加）\n",
    "for col in ['time', 'timestamp', 'ts', 'observed_at', 'event_time']:\n",
    "    if col in vessel.columns:\n",
    "        vessel[col] = pd.to_datetime(vessel[col], errors='coerce')\n",
    "\n",
    "print('Vessel tidy shape:', vessel.shape)\n",
    "print(vessel.head(10))\n",
    "\n",
    "# 快速猜测经纬度列名，方便你确认\n",
    "for lat_key in ['lat','latitude','position.lat','pos.lat','geom.lat','location.lat']:\n",
    "    for lon_key in ['lon','longitude','position.lon','pos.lon','geom.lon','location.lon']:\n",
    "        if lat_key in vessel.columns and lon_key in vessel.columns:\n",
    "            print(f'Found lat/lon columns: {lat_key}, {lon_key}')\n",
    "            print(vessel[[lat_key, lon_key]].head())\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# 可选：挑一组可能的经纬度列名，便于你快速确认\n",
    "for lat_key in ['lat','latitude','position.lat','pos.lat','geom.lat']:\n",
    "    for lon_key in ['lon','longitude','position.lon','pos.lon','geom.lon']:\n",
    "        if lat_key in vessel.columns and lon_key in vessel.columns:\n",
    "            print(f'Found lat/lon columns: {lat_key}, {lon_key}')\n",
    "            print(vessel[[lat_key, lon_key]].head())\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d289b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_min shape: (4210864, 3)\n",
      "ves_min shape: (481, 2)\n",
      "                   time_bin         id  traffic_level\n",
      "0 2025-08-20 06:37:00+00:00  202394085          0.665\n",
      "1 2025-08-20 06:37:00+00:00  202394096          0.435\n",
      "2 2025-08-20 06:37:00+00:00  202394097          0.000\n",
      "3 2025-08-20 06:37:00+00:00  203394034          0.760\n",
      "4 2025-08-20 06:37:00+00:00  203394046          0.760 \n",
      "                    time_bin  vessel_count\n",
      "0 2025-08-20 06:28:00+00:00             3\n",
      "1 2025-08-20 06:29:00+00:00             9\n",
      "2 2025-08-20 06:30:00+00:00             7\n",
      "3 2025-08-20 06:31:00+00:00            15\n",
      "4 2025-08-20 06:32:00+00:00             8\n",
      "tt_ves shape: (4210864, 4)\n",
      "                   time_bin         id  traffic_level  vessel_count\n",
      "0 2025-08-20 06:37:00+00:00  202394085          0.665        2309.0\n",
      "1 2025-08-20 06:37:00+00:00  202394096          0.435        2309.0\n",
      "2 2025-08-20 06:37:00+00:00  202394097          0.000        2309.0\n",
      "3 2025-08-20 06:37:00+00:00  203394034          0.760        2309.0\n",
      "4 2025-08-20 06:37:00+00:00  203394046          0.760        2309.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- 1) 基本类型清洗 ----------\n",
    "# TomTom\n",
    "tomtom['id'] = tomtom['id'].astype('int64')\n",
    "tomtom['traffic_level'] = tomtom['traffic_level'].astype('float32')\n",
    "# 统一时区到 UTC（TomTom 原本是 +02:00）\n",
    "tomtom['time'] = pd.to_datetime(tomtom['time'], utc=True)\n",
    "\n",
    "# Vessel\n",
    "for col in ['upload-timestamp', 'time', 'timestamp', 'ts', 'observed_at', 'event_time']:\n",
    "    if col in vessel.columns:\n",
    "        vessel[col] = pd.to_datetime(vessel[col], utc=True, errors='coerce')\n",
    "# 选一个主时间列（这批数据里有 'upload-timestamp'）\n",
    "vessel['time'] = vessel['upload-timestamp']\n",
    "\n",
    "# 经纬度与数值列\n",
    "for c in ['lat','lon','speed-in-centimeters-per-second','x-speed','y-speed','orientation']:\n",
    "    if c in vessel.columns:\n",
    "        vessel[c] = pd.to_numeric(vessel[c], errors='coerce')\n",
    "\n",
    "# ---------- 2) 统一时间粒度（示例：1 分钟；如需 3 分钟改成 '3min'） ----------\n",
    "BIN = '1min'   # 或者 '3min'\n",
    "tomtom['time_bin'] = tomtom['time'].dt.floor(BIN)\n",
    "vessel['time_bin'] = vessel['time'].dt.floor(BIN)\n",
    "\n",
    "# ---------- 3) 快速聚合 ----------\n",
    "# TomTom：每分钟每 link 的平均 traffic_level（也可改成中位数/最后一个值）\n",
    "tt_min = (tomtom\n",
    "          .groupby(['time_bin','id'], as_index=False)['traffic_level']\n",
    "          .mean())\n",
    "\n",
    "# Vessel：每分钟的船舶数量（全域/也可按网格、缓冲区等聚合）\n",
    "ves_min = (vessel\n",
    "           .groupby('time_bin', as_index=False)\n",
    "           .size()\n",
    "           .rename(columns={'size':'vessel_count'}))\n",
    "\n",
    "print('tt_min shape:', tt_min.shape)\n",
    "print('ves_min shape:', ves_min.shape)\n",
    "print(tt_min.head(), '\\n', ves_min.head())\n",
    "\n",
    "# ---------- 4) 关联（按 time_bin 左连接，得到 traffic 和船数同窗对齐） ----------\n",
    "tt_ves = tt_min.merge(ves_min, on='time_bin', how='left')\n",
    "print('tt_ves shape:', tt_ves.shape)\n",
    "print(tt_ves.head())\n",
    "\n",
    "# ---------- 5) 可选：保存中间结果（后续建模更快） ----------\n",
    "tt_min.to_parquet('data/tt_minute.parquet', index=False)\n",
    "ves_min.to_parquet('data/vessel_minute.parquet', index=False)\n",
    "tt_ves.to_parquet('data/tt_vessel_minute.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df7974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lag_min      corr\n",
      "0        0 -0.435692\n",
      "1        1 -0.444113\n",
      "2        2 -0.444638\n",
      "3        3 -0.451511\n",
      "4        4 -0.454839 \n",
      "    lag_min      corr\n",
      "0        0 -0.452978\n",
      "1        1 -0.453215\n",
      "2        2 -0.452641\n",
      "3        3 -0.448329\n",
      "4        4 -0.452173\n"
     ]
    }
   ],
   "source": [
    "# --- 1) TomTom 全体平均 & Top-N 方差最大的路段 ---\n",
    "# 全体平均\n",
    "tt_all = (tt_min.groupby('time_bin', as_index=False)['traffic_level']\n",
    "          .mean().rename(columns={'traffic_level':'tt_mean'}))\n",
    "\n",
    "# Top-N 波动最大的 link\n",
    "N = 200\n",
    "var_by_id = (tt_min.groupby('id')['traffic_level']\n",
    "             .var().sort_values(ascending=False).head(N).index)\n",
    "tt_top = (tt_min[tt_min['id'].isin(var_by_id)]\n",
    "          .groupby('time_bin', as_index=False)['traffic_level']\n",
    "          .mean().rename(columns={'traffic_level':'tt_topN_mean'}))\n",
    "\n",
    "# --- 2) 与船舶每分钟强度对齐 ---\n",
    "x = ves_min.merge(tt_all, on='time_bin', how='outer').merge(tt_top, on='time_bin', how='outer')\n",
    "x = x.sort_values('time_bin')\n",
    "cols = ['vessel_count','tt_mean','tt_topN_mean']\n",
    "x[cols] = x[cols].ffill()\n",
    "\n",
    "# --- 3) 计算同时 & 滞后相关（例如滞后 0~30 分钟） ---\n",
    "def lag_corr(s1, s2, max_lag=30):\n",
    "    out = []\n",
    "    for k in range(0, max_lag+1):\n",
    "        c = s1.corr(s2.shift(k), method='spearman')  # 对秩更稳健\n",
    "        out.append((k, c))\n",
    "    return pd.DataFrame(out, columns=['lag_min','corr'])\n",
    "\n",
    "lag_all = lag_corr(x['vessel_count'], x['tt_mean'], 30)\n",
    "lag_top = lag_corr(x['vessel_count'], x['tt_topN_mean'], 30)\n",
    "\n",
    "print(lag_all.head(), '\\n', lag_top.head())\n",
    "# 你可以看最大相关对应的滞后分钟数，判断因果方向的线索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5a7a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid shape: (270831, 4)\n",
      "                   time_bin  lat_bin  lon_bin  vessel_cnt\n",
      "0 2025-08-20 06:28:00+00:00      203      772           1\n",
      "1 2025-08-20 06:28:00+00:00      226      679           1\n",
      "2 2025-08-20 06:28:00+00:00      668      826           1\n",
      "3 2025-08-20 06:29:00+00:00       -5      307           1\n",
      "4 2025-08-20 06:29:00+00:00       50       89           1\n"
     ]
    }
   ],
   "source": [
    "# 设定研究范围（用数据的 min/max 也行）\n",
    "lat_min, lat_max = vessel['lat'].quantile([0.01, 0.99])\n",
    "lon_min, lon_max = vessel['lon'].quantile([0.01, 0.99])\n",
    "\n",
    "# 定义网格大小（约 250 m，可按需要调）：经纬度粗换算 ~1度≈111km\n",
    "cell_deg = 0.002  # ~ 200m–250m 在阿姆斯特丹\n",
    "vessel['lat_bin'] = ((vessel['lat'] - lat_min) // cell_deg).astype('Int64')\n",
    "vessel['lon_bin'] = ((vessel['lon'] - lon_min) // cell_deg).astype('Int64')\n",
    "\n",
    "grid = (vessel\n",
    "        .dropna(subset=['lat_bin','lon_bin','time_bin'])\n",
    "        .groupby(['time_bin','lat_bin','lon_bin'], as_index=False)\n",
    "        .size().rename(columns={'size':'vessel_cnt'}))\n",
    "\n",
    "print('grid shape:', grid.shape)\n",
    "print(grid.head())\n",
    "# 这张表就是“每分钟 × 网格”的船舶密度；之后有了道路几何，只需要把每条路段的缓冲区落到若干网格汇总即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "854c21df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL  best lag: 58 rho= -0.533\n",
      "TopN best lag: 58 rho= -0.477\n"
     ]
    }
   ],
   "source": [
    "def lag_corr_series(s1, s2, max_lag=60, method='spearman'):\n",
    "    out = []\n",
    "    for k in range(0, max_lag+1):\n",
    "        out.append((k, s1.corr(s2.shift(k), method=method)))\n",
    "    return pd.DataFrame(out, columns=['lag_min','corr'])\n",
    "\n",
    "lag_all = lag_all.rename(columns={'corr': 'rho'})\n",
    "lag_top = lag_top.rename(columns={'corr': 'rho'})\n",
    "\n",
    "best_all = lag_all.loc[lag_all['rho'].abs().idxmax()]\n",
    "best_top = lag_top.loc[lag_top['rho'].abs().idxmax()]\n",
    "\n",
    "print('ALL  best lag:', int(best_all['lag_min']), 'rho=', round(float(best_all['rho']), 3))\n",
    "print('TopN best lag:', int(best_top['lag_min']), 'rho=', round(float(best_top['rho']), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffe8e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag_min    79.000000\n",
      "rho_A      -0.573713\n",
      "rho_B      -0.461175\n",
      "Name: 79, dtype: float64\n",
      "lag_min    31.000000\n",
      "rho_A      -0.505043\n",
      "rho_B      -0.489442\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def lag_corr_bidir(s1, s2, max_lag=90, method='spearman'):\n",
    "    # dirA: vessel leads -> corr( vessel(t), tt(t+k) )\n",
    "    A = [(k, s1.corr(s2.shift(k), method=method)) for k in range(max_lag+1)]\n",
    "    A = pd.DataFrame(A, columns=['lag_min','rho_A'])  # vessel -> tt\n",
    "\n",
    "    # dirB: tt leads -> corr( tt(t), vessel(t+k) )\n",
    "    B = [(k, s2.corr(s1.shift(k), method=method)) for k in range(max_lag+1)]\n",
    "    B = pd.DataFrame(B, columns=['lag_min','rho_B'])  # tt -> vessel\n",
    "\n",
    "    return A.merge(B, on='lag_min')\n",
    "\n",
    "lag_bi = lag_corr_bidir(x['vessel_count'], x['tt_mean'], max_lag=90)\n",
    "print(lag_bi.loc[lag_bi['rho_A'].abs().idxmax()])\n",
    "print(lag_bi.loc[lag_bi['rho_B'].abs().idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866b7d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag_min     79.000000\n",
      "rho_detr    -0.104362\n",
      "Name: 79, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 15分钟滚动去均值\n",
    "x_dt = x[['time_bin','vessel_count','tt_mean']].copy()\n",
    "x_dt['vessel_detr'] = x_dt['vessel_count'] - x_dt.set_index('time_bin')['vessel_count'].rolling('15min').mean().values\n",
    "x_dt['tt_detr']     = x_dt['tt_mean']     - x_dt.set_index('time_bin')['tt_mean'].rolling('15min').mean().values\n",
    "\n",
    "lag_dt = [(k, x_dt['vessel_detr'].corr(x_dt['tt_detr'].shift(k), method='spearman')) for k in range(91)]\n",
    "lag_dt = pd.DataFrame(lag_dt, columns=['lag_min','rho_detr'])\n",
    "print(lag_dt.loc[lag_dt['rho_detr'].abs().idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00d4d789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-min BIN best lag_k: 89 ≈ 267 min, rho= 0.806\n",
      "Detrended best lag ≈ 120 min, rho= -0.215\n",
      "ΔR² = 0.0051, coef(lag_k=89, ~267min) = -0.000001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1) 统一到 3 分钟粒度（更贴近 TomTom 原节拍），并用 inner join 避免 ffill 引入趋势 ---\n",
    "BIN = '3min'\n",
    "tomtom['time_bin'] = tomtom['time'].dt.floor(BIN)\n",
    "vessel['time_bin'] = vessel['time'].dt.floor(BIN)\n",
    "\n",
    "tt_min = tomtom.groupby(['time_bin','id'], as_index=False)['traffic_level'].mean()\n",
    "ves_min = vessel.groupby('time_bin', as_index=False).size().rename(columns={'size':'vessel_count'})\n",
    "\n",
    "# 全体平均 traffic\n",
    "tt_all = tt_min.groupby('time_bin', as_index=False)['traffic_level'].mean() \\\n",
    "               .rename(columns={'traffic_level':'tt_mean'})\n",
    "\n",
    "# 保持“公共时间交集”，避免 ffill\n",
    "x = pd.merge(tt_all, ves_min, on='time_bin', how='inner').sort_values('time_bin').reset_index(drop=True)\n",
    "\n",
    "# 若存在缺口，用正规重采样+插值/短窗口均值（可选）\n",
    "# x = x.set_index('time_bin').resample(BIN).mean().interpolate(limit=2).dropna().reset_index()\n",
    "\n",
    "# --- 2) 滞后相关：正确标注分钟单位 ---\n",
    "FREQ_MIN = pd.to_timedelta(BIN).seconds // 60  # 3\n",
    "def lag_corr_series(s1, s2, max_lag=90, method='spearman'):\n",
    "    rows = []\n",
    "    for k in range(max_lag+1):\n",
    "        rows.append((k, k*FREQ_MIN, s1.corr(s2.shift(k), method=method)))\n",
    "    return pd.DataFrame(rows, columns=['lag_k','lag_min','rho'])\n",
    "\n",
    "lag3 = lag_corr_series(x['vessel_count'], x['tt_mean'], 90)\n",
    "best3 = lag3.loc[lag3['rho'].abs().idxmax()]\n",
    "print('3-min BIN best lag_k:', int(best3['lag_k']),\n",
    "      '≈', int(best3['lag_min']), 'min, rho=', round(float(best3['rho']),3))\n",
    "\n",
    "# --- 3) 去趋势 + 小时固定效应 检查 ---\n",
    "# 去趋势：滚动 15 分钟窗口（=5个3min样本）\n",
    "roll = f'{5*FREQ_MIN}min'  # '15min'\n",
    "xx = x.copy()\n",
    "xx['vessel_detr'] = xx['vessel_count'] - xx.set_index('time_bin')['vessel_count'].rolling(roll).mean().values\n",
    "xx['tt_detr']     = xx['tt_mean']      - xx.set_index('time_bin')['tt_mean'].rolling(roll).mean().values\n",
    "\n",
    "lag_dt = lag_corr_series(xx['vessel_detr'], xx['tt_detr'], 90)\n",
    "best_dt = lag_dt.loc[lag_dt['rho'].abs().idxmax()]\n",
    "print('Detrended best lag ≈', int(best_dt['lag_min']), 'min, rho=', round(float(best_dt['rho']),3))\n",
    "\n",
    "# 小时固定效应 + 滞后（sklearn 近似版）\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df = x[['time_bin','tt_mean','vessel_count']].dropna().copy()\n",
    "df['hour'] = df['time_bin'].dt.tz_convert('Europe/Amsterdam').dt.hour\n",
    "\n",
    "LAG_K = int(best3['lag_k'])  # 用上面找到的滞后（k 步），你也可以手动填 58/79 做对照\n",
    "df[f'vessel_lag_k'] = df['vessel_count'].shift(LAG_K)\n",
    "df = df.dropna()\n",
    "\n",
    "H = pd.get_dummies(df['hour'].astype('category'), drop_first=True)\n",
    "\n",
    "X0 = H.values\n",
    "y  = df['tt_mean'].values\n",
    "m0 = LinearRegression().fit(X0, y)\n",
    "r2_0 = m0.score(X0, y)\n",
    "\n",
    "X1 = np.column_stack([H.values, df['vessel_lag_k'].values])\n",
    "m1 = LinearRegression().fit(X1, y)\n",
    "r2_1 = m1.score(X1, y)\n",
    "\n",
    "print(f'ΔR² = {r2_1 - r2_0:.4f}, coef(lag_k={LAG_K}, ~{LAG_K*FREQ_MIN}min) = {m1.coef_[-1]:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09acaa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ΔR² = 0.0061, coef(lag79) = -0.0000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asof lag0 spearman = -0.4812036724525778\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dae64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL6022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
